





import pandas as pd
#we can simply load csv file or we can load it from url as below
# A valid CSV URL from a public GitHub repo
url = "https://raw.githubusercontent.com/YBI-Foundation/Dataset/main/Titanic.csv"  # Titanic dataset :contentReference[oaicite:0]{index=0}

df = pd.read_csv(url)

print(df.info())
print(df.shape)














df = pd.read_csv('imdb-top-1000.csv',usecols=['Series_Title', 'IMDB_Rating','No_of_Votes','Released_Year'])
df.head()
df.sort_values(ascending=False,by='IMDB_Rating')





























import pandas as pd
pd.read_json('archive/test.json')


#we can also fetch from link like
pd.read_json('https://dummyjson.com/products')





#practical Example
import pandas as pd
# import mysql.connector

# Connect to database
# connection = mysql.connector.connect(
#     host="localhost",
#     user="root",
#     password="1234",
#     database="student_db"
# )

# SQL query
# query = "SELECT * FROM students;"

# Fetch data
# df = pd.read_sql(query, connection)

# Print first 5 rows
# print(df.head())

# Close connection
# connection.close()






import requests
import pandas as pd
res = requests.get('https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page=1')

df = pd.DataFrame(res.json()['results'])[['title','release_date','overview','vote_average','vote_count']]


df


import numpy as np
dfs = []
for i in range(1,526):
    res = requests.get('https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page={}'.format(i))
    df = pd.DataFrame(res.json()['results'])[['title','release_date','overview','vote_average','vote_count']]
    dfs.append(df)
all_df = pd.concat(dfs, ignore_index=True)



all_df



