











# -----------------------------
# 1. Import Libraries
# -----------------------------
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# -----------------------------
# 2. Generate Dataset (100 rows)
# -----------------------------
np.random.seed(42)

# Features
age = np.random.randint(20, 61, 100)        # Age: 20-60

# Target: Purchased (0 or 1) with some randomness
salary = np.random.randint(20000, 200001, 100)  # bigger range
threshold = 50
purchased = ((age + salary/5000 + np.random.normal(0, 10, 100)) > 50).astype(int)



# Create DataFrame
df = pd.DataFrame({
    'Age': age,
    'Salary': salary,
    'Purchased': purchased
})

# Features & target
X = df[['Age', 'Salary']]
y = df['Purchased']

# -----------------------------
# 3. Train-Test Split (with stratify!)
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

print("Train class distribution:\n", y_train.value_counts())
print("Test class distribution:\n", y_test.value_counts())

# -----------------------------
# 4. Logistic Regression WITHOUT Scaling
# -----------------------------
clf_lr_raw = LogisticRegression()
clf_lr_raw.fit(X_train, y_train)
y_pred_lr_raw = clf_lr_raw.predict(X_test)
acc_lr_raw = accuracy_score(y_test, y_pred_lr_raw)

print("\nLogistic Regression Accuracy WITHOUT Scaling:", acc_lr_raw)

# -----------------------------
# 5. Apply StandardScaler
# -----------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------
# 6. Logistic Regression WITH Scaling
# -----------------------------
clf_lr_scaled = LogisticRegression()
clf_lr_scaled.fit(X_train_scaled, y_train)
y_pred_lr_scaled = clf_lr_scaled.predict(X_test_scaled)
acc_lr_scaled = accuracy_score(y_test, y_pred_lr_scaled)

print("Logistic Regression Accuracy WITH Scaling   :", acc_lr_scaled)

# -----------------------------
# 7. KNN WITHOUT Scaling
# -----------------------------
clf_knn_raw = KNeighborsClassifier(n_neighbors=5)
clf_knn_raw.fit(X_train, y_train)
y_pred_knn_raw = clf_knn_raw.predict(X_test)
acc_knn_raw = accuracy_score(y_test, y_pred_knn_raw)

print("\nKNN Accuracy WITHOUT Scaling:", acc_knn_raw)

# -----------------------------
# 8. KNN WITH Scaling
# -----------------------------
clf_knn_scaled = KNeighborsClassifier(n_neighbors=5)
clf_knn_scaled.fit(X_train_scaled, y_train)
y_pred_knn_scaled = clf_knn_scaled.predict(X_test_scaled)
acc_knn_scaled = accuracy_score(y_test, y_pred_knn_scaled)

print("KNN Accuracy WITH Scaling   :", acc_knn_scaled)















df = pd.read_csv('wine_data.csv',header=None,usecols=[0,1,2])
df
df.columns = ['Class label', 'Alcohal','Malic acid']


df


import seaborn as sns
sns.kdeplot(df['Alcohal'])


sns.kdeplot(df['Malic acid'])


# scater plot
color_dict = {1:'red',3:'green',2:'blue'}
sns.scatterplot(data=df,x='Alcohal',y='Malic acid',hue=df['Class label'],palette=color_dict)





from sklearn.model_selection import train_test_split
X_train, X_test,y_train,y_test = train_test_split(df.drop('Class label', axis=1),
                                                 df['Class label'],
                                                 test_size=0.3,
                                                 random_state=0)
X_train.shape, X_test.shape


#minMaxScalar
from sklearn.preprocessing import MinMaxScaler
scalar = MinMaxScaler()

#fit the scalar to the train set, it will learn the perameters
scalar.fit(X_train)

#transform train and test sets
X_train_scaled = scalar.transform(X_train)
X_test_scaled = scalar.transform(X_test)


X_train_scaled = pd.DataFrame(X_train_scaled,columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled,columns=X_test.columns)


#old unscaled
np.round(X_train.describe(),1)
#new scalad
np.round(X_train_scaled.describe(),1) # normalization => to bring in fix range i.e 0 and 1
























